# UD02 2. Comandos HDFS

> [!NOTE] ATENCIÓN
> Hay que asegurarse que está arrancado HDFS

El comando hdfs se encuentra de la carpeta `/opt/hadoop/bin`y el sistema busca en esta carpeta porque la habíamos incluido en nuestro `$PATH`.

Mostramos todas las opciones posibles del comando `hdfs dfs`.
El comando hdfs "emula" comandos Linux como verás posteriormente.

```bash
$ echo $PATH

$ hdfs dfs #Muestra todos los comandos posibles

```
![](<./images/comando_hdfs_dfs.png>)

Para visualizar el contenido actual del sistema de ficheros HDFS.

```bash
$ hdfs dfs -ls /
```

**Ejercicio 1:**
- Crear un fichero simple en local (prueba.txt).
- Crear un directorio en el sistema de ficheros DFS (temporal)
- Copiar el archivo que hemos creado al directorio remoto.

- **Solución**
```bash
## Creamos un archivo con contenido
$ echo "Hola" > prueba.txt
$ hdfs dfs -mkdir /temporal
$ hdfs dfs -ls /
# Subimos un fichero de nuestro sistema a HDFS
$ hdfs dfs -put prueba.txt /temporal 
$ hdfs dfs -ls /
```

Desde el explorador la web de administración, podemos ver información del archivo y bloques.
![](<./images/comandos1.png>)

Nos fijamos en `Bloock ID`  y `Bloock Pool`

**¿Cómo hacerlo a través de un comando?**

```bash
$ hdfs fsck /temporal/prueba.txt -files -blocks
  
Connecting to namenode via http://debianh:9870/fsck?ugi=hadoop&files=1&blocks=1&path=%2Fhola.txt
    FSCK started by hadoop (auth:SIMPLE) from /127.0.0.1 for path /hola.txt at Mon Nov 06 14:08:52 CET 2023
    
/temporal/prueba.txt 5 bytes, replicated: replication=1, 1 block(s):  OK
 0. **BP-673766993-127.0.1.1-1698337131957**:blk_**1073741825**_1001 len=5 Live_repl=1
```


Ahora vamos a comprobar cómo HDFS ha guardado el archivo en local. Para ello vamos a:
```bash
$ cd /datos/datanode/current
```

Encontraremos una carpeta con el mismo nombre que el `Bloock Pool`, en mi caso entraré con:

```bash
cd BP-673766993-127.0.1.1-1698337131957
# Accedemos a sus subdirectorios
cd current/finalized/subdir0/subdir0/ 
```

En este momento podremos ver el bloque que debe encajar con el `Block ID`

```bash
$ ls
blk_1073741825

$ cat blk_1073741825
hola
```

Podemos borrar todo recursivamente con:
```bash
hdfs dfs -rm -r /temporal
```


## Errores

**No aparece información del archivo**
![](<./images/errores1.png>)
Se trata de un archivo vacío.
