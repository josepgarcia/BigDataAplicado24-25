# 2. Descarga y configuración Hadoop.

## 1. Descarga + “instalación” de hadoop

Información y descargas:

[https://hadoop.apache.org/](https://hadoop.apache.org/)

![](<./images/descargahadoop1.png>)
---

<aside>
ℹ️ Tutorial digitalocean
[https://www.digitalocean.com/community/tutorials/how-to-install-hadoop-in-stand-alone-mode-on-ubuntu-20-04](https://www.digitalocean.com/community/tutorials/how-to-install-hadoop-in-stand-alone-mode-on-ubuntu-20-04)

</aside>

Descargamos Hadoop (Binary download)

[https://hadoop.apache.org/releases.html](https://hadoop.apache.org/releases.html)


![](<./images/descargahadoop2.png>)

- Copiamos la URL con la última versión, **¿Qué version descargar?**
    
    Instalaciones por defecto
    
    [https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz](https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz)
    
    Instalación en un MAC m1 o m2 (procesador ARM)
    
    [https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6-aarch64.tar.gz](https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6-aarch64.tar.gz)
    
    <aside>
    ⚠️ Pendiente, verificar archivo descargado con la firma
    
    </aside>
    

Desde ssh a la máquina virtual, como **root**:

```bash
cd /opt

# Descargamos
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz

# Descomprimimos
tar -zxvf hadoop-3.3.6.tar.gz
ls -la

# Creamos un enlace para trabajar de manera más cómoda
ln -s hadoop-3.3.6 hadoop
ls -la

# Cambiamos el propietario y grupo de la carpeta y enlace creado
# En el documento anterior creamos el usuario hadoop
chown -R hadoop:hadoop hadoop-3.3.6 hadoop

# Entramos a la carpeta descomprimida (a través del enlace creado)
cd hadoop
```

---

Accedemos ahora a la máquina con usuario **hadoop** y modificamos de nuevo el archivo .bashrc, le añadimos las siguientes líneas:

```bash
# HADOOP_HOME sin barra final
export HADOOP_HOME=/opt/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

**#### NO AÑADIR DE MOMENTO ESTAS VARIABLES**

export HADOOP_MAPRED_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
export HADOOP_STREAMING=$HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.2.3.jar
export HADOOP_LOG_DIR=$HADOOP_HOME/logs
export PDSH_RCMD_TYPE=ssh

Recargamos .bashrc saliendo y volviendo a entrar o mediante:

```bash
source .bashrc
```

Si todo ha ido bien ya podremos ejecutar hadoop:

```bash
hadoop -h

hadoop version
```

## 2. Directorios dentro de Hadoop

```
/opt/hadoop/bin -> "ejecutables"
	hadoop, hdfs, mapred, yar

/opt/hadoop/etc -> ficheros de configuracion xml

/opt/hadoop/lib -> librerías nativas

/opt/hadoop/sbin -> scripts, utilidades que me permiten entre otras cosas arrancar y parar hadoop

/opt/hadoop/share -> paquetes, ejemplos ...
```

## 3. Comprobar que hadoop funciona

Para comprobar que `mapreduce` funciona, vamos a ejecutar unos ejemplos que podemos encontrar dentro de share.

```bash
$ pwd
/opt/hadoop/share/hadoop/mapreduce

# Podemos ver los ejemplos que se pueden ejecutar ejecutando sobre el paquete de ejemplos mapreduce
$ jar tf hadoop-mapreduce-examples-3.3.6.jar
# Nos sale un listado de todos los comandos u opciones de este paquete

#### Vamos a ejecutar por ejemplo: 
#### org/apache/hadoop/examples/Grep.class

# Preparamos los directorios donde estarán los datos de entrada (en /tmp) y copiamos datos de entrada "demo",
# por ejemplo ficheros de configuración de hadoop
$ mkdir /tmp/entrada
$ cd /tmp/entrada
$ cp /opt/hadoop/etc/hadoop/*.xml .

## Vamos a buscar (tal y como hace grep), las palabras que contengan un determiando texto, en este caso
## palabras que contengan el texto kms
$ cd /opt/hadoop/share/hadoop/mapreduce/

## Invocamos al paquete de ejemplos, comando grep
$ hadoop jar hadoop-mapreduce-examples-3.3.6.jar grep /tmp/entrada /tmp/salida/ 'kms'

## Hace una serie de procesos mapper y reducer (lo veremos más adelante)
$ cd /tmp/salida/
$ ls
part-r-00000  _SUCCESS

# _SUCCESS -> ha sido satisfactorio

# ¿Cuántas veces ha encontrado la palabra kms?
$ cat part-r-00000
9	kms

-------------------------------------------------
# Se trata de un programa básico inicial para comprobar que funciona, podemos hacer lo mismo desde bash:
cd /tmp/entrada
egrep kms * | wc -l
```

## 4. Posibles Errores

**ERROR 1**
El directorio /tmp/salida ya existe, dará error si no se borra

**ERROR 2
Cannot execute /home/debian/hadoop-3.2.3//libexec/hadoop-config.sh**
En .bashrc hemos añadido una barra al final de HADOOP_HOME
Modificar archivo, guardar cambios y luego ejecutar: source .bashrc (para que los cambios se apliquen a la sesión)
ERROR: JAVA_HOME /usr/lib/jvm/java-17-openjdk-amd64 does not exist
La variable de sesión JAVA_HOME no es correcta, revisa la carpeta de java

**ERROR 3**
**ERROR: JAVA_HOME /usr/lib/jvm/java-17-openjdk-amd64 does not exist**
La variable de sesión JAVA_HOME no es correcta, revisa la carpeta de java