# Hadoop Ventas

Para comprender mejor cómo funciona un trabajo típico de Hadoop basado en MapReduce, a continuación profundizaremos en la programación y ejecución de un ejemplo utilizando el lenguaje Python.

Hadoop funciona de forma nativa con Java pero cuenta con una herramienta que permite la ejecución de programas/scripts en diferentes lenguajes como python. Esta es la herramienta "Streaming": [https://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html](https://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html)
Este ejemplo trabaja con un conjunto de datos relacionados con las ventas de una empresa con múltiples tiendas: `purchases.txt`

Lo puedes descargar en:
[https://github.com/josepgarcia/datos](https://github.com/josepgarcia/datos)

A continuación puede ver un extracto del archivo, que contiene seis campos sobre compras: fecha, hora, ubicación de la tienda, categoría de producto, compra total y método de pago.

```
2012-01-01	09:00	San Jose	Men's Clothing	214.05	Amex
2012-01-01	09:00	Fort Worth	Women's Clothing	153.57	Visa
2012-01-01	09:00	San Diego	Music	66.08	Cash
2012-01-01	09:00	Pittsburgh	Pet Supplies	493.51	Discover
2012-01-01	09:00	Omaha	Children's Clothing	235.63	MasterCard
2012-01-01	09:00	Stockton	Men's Clothing	247.18	MasterCard
2012-01-01	09:00	Austin	Cameras	379.6	Visa
2012-01-01	09:00	New York	Consumer Electronics	296.8	Cash
2012-01-01	09:00	Corpus Christi	Toys	25.38	Discover
2012-01-01	09:00	Fort Worth	Toys	213.88	Visa
```

## Ejemplo 1: Fase 1

Queremos saber el importe total de ventas de cada tienda (la tienda corresponde a la tercera columna del archivo, hay una tienda por ciudad).

El paradigma MapReduce tiene 3 pasos: 
mapper()
shuffle - sort
reducer()

**mapper**
El mapper estará a cargo de construir el par clave:valor de cada línea. Piensa que cada nodo del cluster ejecutará el mapper en las líneas del archivo que le corresponden. En cualquier caso, es un trabajo que se ejecuta por líneas, lo que **permite una fácil paralelización**.

Nuestro mapper debe devolver como clave el nombre de la tienda y como valor el importe de las ventas. Por ejemplo:
```
San José    214,05
Fort Worth    153,57
...
Fort Worth    213,88
```

**shuffle - sort**
Sustituiremos esta fase por el comando sort, por lo que simplemente haremos un:

```bash
cat salida_mapper.csv | sort > salida_sort.csv
```

**reducer**
El reducer se encargará de sumar los valores correspondientes a cada clave.
La salida será, por ejemplo:
```
San José    214.05
Fort Worth    367,45       # (135,57+213,88)
```


> [!NOTE] Ejercicio
> Programa el **mapper** y **reducer** con python, ten en cuenta que cuando los datos lleguen al reducer estarán ordenados (se realizará un sort antes).

**Ejemplo de funcionamiento**

```bash
python mapper.py 

San Jose	214.05
Fort Worth	153.57
San Diego	66.08
Pittsburgh	493.51
Omaha	235.63
Stockton	247.18
Austin	379.6
New York	296.8

# Lo guardamos en un archivo intermedio
python mapper.py > salida_mapper.txt

# Hacemos el shuffle + sort "manualmente"
cat salida_mapper.txt| sort > salida_sort.txt

# El archivo salida_sort debe contener los datos ordenados
#Albuquerque	440.7
#Anchorage	22.36
#Anchorage	298.86
#Anchorage	368.42
#Anchorage	390.2
#Anchorage	6.38
#Atlanta	254.62

# Hacemos el reducer
python3 reducer_simple.py

Albuquerque 	 440.7 # suma de todas las líneas con clave Albuquerque
Anchorage 	 1086.2200000000003
Atlanta 	 254.62
Aurora 	 117.81
Austin 	 1304.7800000000002
Boise 	 481.09000000000003
Boston 	 418.94

```

## Ejemplo 1: Fase 2

Uso de tuberías.
Para que podamos ejecutar el programa a través de hadoop, ha de hacer uso de tuberías no de ficheros.

Modifica el código para que en vez de leer de un fichero lea del stream de entrada (sys.stdin)

Puedes comprobar el funcionamiento ejecutando:
```bash
cat purchases.txt | python mapper.py | sort | python reducer.py > salida.txt
```

## Ejemplo 1: Fase 3

Mejora el código:

- [ ] Todas las líneas del archivo de entrada deben tener el mismo número de campos, si no es así en alguna línea hay que descartarla. 
- [ ] Asegúrate que el valor numérico sea float. 
- [ ] Como se ha mencionado anteriormente, hay que tener en cuenta que al **reducer** le llegan los datos ordenados.
- [ ] ¿Otras mejoras?

## Ejemplo 1: Fase 4

Ejecución en el cluster.

## Ejercicios


> [!NOTE] Entregables 
> Entregables en AULES

### Ejercicio 1

Redefine el mapper para que mapreduce devuelva como salida las ventas totales por categoría.

```
**Ejemplo de resultado (datos no reales):**

Pet Supplies   1123.4  
Music          22344.56
Clothing       3356.45
```

### Ejercicio 2 

Redefine el mapper y reducer para que se obtenga la venta más alta para cada tipo de pago de las registradas en todo el archivo.

**No hay que devolver las ventas totales por tipo de pago**

```
**Ejemplo de resultado (datos no reales):**

Visa           133.5   -> la venta más alta de todas las hechas con visa
Cash           223.56  -> la venta más alta de todas las hechas con cash
Mastercard     1356.45 -> la venta más alta de todas las hechas con Mastercard
```

###  Ejercicio 3

Realiza las modificaciones necesarias para que mapreduce nos devuelve la venta más alta de todas las realizadas

### Ejercicio 4
Redefine los scripts para que se obtengan las ventas totales.
